{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Úkol č. 4 - regrese (do 14. ledna, nejpozději však před zkouškou)\n",
    "\n",
    "  * Cílem tohoto úkolu je vyzkoušet si řešit regresní problém na reálných (ale celkem vyčištěných) datech.\n",
    "  \n",
    "> **Nejdůležitější na úkolu je to, abyste udělali vše procesně správně: korektní rozdělení datasetu, ladění hyperparametrů, vyhodnocení výsledků atp.**\n",
    "\n",
    "## Dataset\n",
    "\n",
    "  * Zdroj dat je zde: https://data.world/uci/online-news-popularity.\n",
    "  * Popis datasetu najdete v souboru `data_description.txt`.\n",
    "  \n",
    "\n",
    "## Pokyny k vypracování\n",
    "\n",
    "**Základní body zadání**, za jejichž (poctivé) vypracování získáte **8 bodů**:\n",
    "  * Proveďte základní průzkum dat a příp. vyhoďte nezajímavé příznaky.\n",
    "  * Aplikujte lineární a hřebenovou regresi a výsledky řádně vyhodnoťte:\n",
    "    * K měření chyby použijte `median_absolute_error`, bezpracné použití lineární regrese dává chybu zhruba 1700, Vaším úkolem je toto zlepšit.\n",
    "    * Experimentujte s tvorbou nových příznaků (na základě těch dostupných).\n",
    "    * Experimentujte se standardizací/normalizací dat.\n",
    "    * Vyberte si hyperparametry modelů k ladění a najděte jejich nejlepší hodnoty.\n",
    "\n",
    "**Další body zadání** za případné další body (můžete si vybrat, maximum bodů za úkol je každopádně 12 bodů):\n",
    "  * (až +4 body) Použijte i jiné metody než je lineární a hřebenová regrese.\n",
    "  * (až +4 body) Získejte opravdu dobré výsledky (ve srovnání s Vašimi kolegy).\n",
    "\n",
    "## Poznámky k odevzdání\n",
    "\n",
    "  * Řiďte se pokyny ze stránky https://courses.fit.cvut.cz/BI-VZD/homeworks/index.html.\n",
    "  * Odevzdejte pouze tento Jupyter Notebook, opravujíví by neměl nic jiného potřebovat.\n",
    "  * Opravující Vám může umožnit úkol dodělat či opravit a získat tak další body. První verze je ale důležitá a bude-li odbytá, budete za to penalizováni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from scipy.optimize import minimize_scalar\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import numpy as np\n",
    "np.warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import robust_scale\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import quantile_transform\n",
    "from sklearn.preprocessing import power_transform\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data):\n",
    "    return train_test_split(data.drop(columns = ['shares']), data['shares'], test_size=0.25, random_state = 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v dokumentaci se pise, ze priznaky url a timedelta neovlivnuji shares, tak je mazu\n",
    "# dale delim data na trenovaci a na konecne testovaci\n",
    "df = pd.read_csv('data.csv')\n",
    "df.columns = [col.strip() for col in df.columns]\n",
    "\n",
    "df = df.drop(['url','timedelta'],axis=1)\n",
    "X_first_train, X_final_test, Y_first_train, Y_final_test = split_data(df)\n",
    "X_first = pd.concat([X_first_train,Y_first_train],axis=1)\n",
    "X_first = X_first.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vytvorim si list s linearni zavislosti na priznak shares\n",
    "def linear_corr_train(data):\n",
    "    a = data.corr().shares\n",
    "    a = abs(a)\n",
    "    a = a.sort_values(ascending=False)\n",
    "    a.drop(a.head(1).index,inplace=True)\n",
    "    return a\n",
    "\n",
    "# ruzne zmeny dat\n",
    "\n",
    "# vytvarim nove priznaky nasobenim jiz existujicich (podle list zavislosti) a pak mazu ty na spodu listu \n",
    "def data_change_1_do(data,names):\n",
    "    res = data.copy()\n",
    "    j = names.size\n",
    "    for i in range(21):\n",
    "        j = j - 1\n",
    "        res[i] = res[names.index[j]] * res[names.index[i]]\n",
    "    res =  res.drop(names.tail(20).index,axis=1)   \n",
    "    return res\n",
    "\n",
    "# vytvarim nove priznaky nasobenim priznaku (vedle sebe v listu zavislosti)\n",
    "def data_change_2_do(data,names):\n",
    "    res = data.copy()\n",
    "    for i in range(0,names.size,2):\n",
    "        res[i] = res[names.index[i]] * res[names.index[i+1]]\n",
    "    return res\n",
    "\n",
    "\n",
    "# mazu priznaky na spodu listu\n",
    "def data_change_3_do(data,names):\n",
    "    res = data.drop(names.tail(20).index,axis=1)\n",
    "    return res\n",
    "\n",
    "# nic nedelam\n",
    "def data_change_4_do(data,names):\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruzna skalovani dat\n",
    "\n",
    "def quantil(data):\n",
    "    return quantile_transform(data)\n",
    "def power(data):\n",
    "    return power_transform(data, method ='yeo-johnson')\n",
    "def robust(data):\n",
    "    return robust_scale(data)\n",
    "def standard_scale(data):\n",
    "    return scale(data)\n",
    "def normal(data):\n",
    "    return normalize(data)\n",
    "def nothing(data):\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dale se nachazeji ruzne regresni modely\n",
    "# kvuli rychlosti jsem u volby hyperparametru omezil parametry jenom na jednu nebo par moznosti\n",
    "\n",
    "def neural(train_X,train_Y,test_X,test_Y):\n",
    "    param_grid = {\n",
    "        'hidden_layer_sizes': [(50,)],\n",
    "        'random_state':  range(3,4,1)\n",
    "    }\n",
    "    param_comb = ParameterGrid(param_grid)\n",
    "    \n",
    "    def get_neural_clf(X_cvs,Y_cvs):\n",
    "        \n",
    "        def neuralmodel(param):\n",
    "            clf = MLPRegressor(**param)\n",
    "            return -np.mean(cross_val_score(clf,X_cvs,Y_cvs,scoring='neg_median_absolute_error',cv=3))\n",
    "                \n",
    "        params_res = []\n",
    "        for param in param_comb:\n",
    "            params_res.append(neuralmodel(param))\n",
    "        return param_comb[params_res.index(np.min(params_res))]\n",
    "    \n",
    "    params_res = get_neural_clf(train_X,train_Y)\n",
    "    reg = MLPRegressor(**params_res).fit(train_X,train_Y)\n",
    "    return predict(reg,test_X,test_Y),reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdaBoost(train_X,train_Y,test_X,test_Y):\n",
    "    param_grid = {\n",
    "        'n_estimators': range(30,40,20),\n",
    "        'learning_rate': [0.05 ]\n",
    "    }\n",
    "    param_comb = ParameterGrid(param_grid)\n",
    "    \n",
    "    def get_forest_clf(X_cvs,Y_cvs):\n",
    "        \n",
    "        def forestmodel(param):\n",
    "            clf = AdaBoostRegressor(**param)\n",
    "            return -np.mean(cross_val_score(clf,X_cvs,Y_cvs,scoring='neg_median_absolute_error',cv=3))\n",
    "                \n",
    "        params_res = []\n",
    "        for param in param_comb:\n",
    "            params_res.append(forestmodel(param))\n",
    "        return param_comb[params_res.index(np.min(params_res))]\n",
    "    \n",
    "    params_res = get_forest_clf(train_X,train_Y)\n",
    "    reg = AdaBoostRegressor(**params_res).fit(train_X,train_Y)\n",
    "    return predict(reg,test_X,test_Y),reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForest(train_X,train_Y,test_X,test_Y):\n",
    "    param_grid = {\n",
    "        'n_estimators': range(30,40,20),\n",
    "        'max_depth': range(2,3)\n",
    "    }\n",
    "    param_comb = ParameterGrid(param_grid)\n",
    "    \n",
    "    def get_forest_clf(X_cvs,Y_cvs):\n",
    "        \n",
    "        def forestmodel(param):\n",
    "            clf = RandomForestRegressor(**param)\n",
    "            return -np.mean(cross_val_score(clf,X_cvs,Y_cvs,scoring='neg_median_absolute_error',cv=3))\n",
    "        \n",
    "        params_res = []\n",
    "        for param in param_comb:\n",
    "            params_res.append(forestmodel(param))\n",
    "        return param_comb[params_res.index(np.min(params_res))]\n",
    "    params_res = get_forest_clf(train_X,train_Y)\n",
    "    reg = RandomForestRegressor(**params_res).fit(train_X,train_Y)\n",
    "    return predict(reg,test_X,test_Y),reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(train_X,train_Y,test_X,test_Y):\n",
    "    reg = LinearRegression().fit(train_X, train_Y)\n",
    "    return predict(reg,test_X,test_Y),reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hreben(train_X,train_Y,test_X,test_Y):\n",
    "    param_grid = {\n",
    "        'alpha': np.arange(1.0, 10.0, 0.5)\n",
    "    }\n",
    "    param_comb = ParameterGrid(param_grid)\n",
    "    \n",
    "    \n",
    "    def get_ridge_clf(X_cvs,Y_cvs):\n",
    "        \n",
    "        def ridgemodel(param):\n",
    "            clf = Ridge(**param)\n",
    "            return -np.mean(cross_val_score(clf,X_cvs,Y_cvs,scoring='neg_median_absolute_error',cv=3))\n",
    "        \n",
    "        params_res = []\n",
    "        for param in param_comb:\n",
    "            params_res.append(ridgemodel(param))\n",
    "        return param_comb[params_res.index(np.min(params_res))]\n",
    "    \n",
    "    params_res = get_ridge_clf(train_X,train_Y)\n",
    "    reg = Ridge(**params_res).fit(train_X, train_Y)\n",
    "    return predict(reg,test_X,test_Y),reg    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(reg,test_X,test_Y):\n",
    "    predict = reg.predict(test_X)\n",
    "    return median_absolute_error(test_Y,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kombinuji vsechny moje moznosti upravy dat a modely\n",
    "# vsechny vysledky uschovavam do listu vys\n",
    "\n",
    "# kvuli rychlosti jsou momentalne spustene jen linearni a hrebenove regrese s upravou dat, u kterych davaly nejlepsi vysledek\n",
    "\n",
    "data_changes = [data_change_2_do]\n",
    "#data_changes = [data_change_1_do,data_change_2_do,data_change_3_do,data_change_4_do]\n",
    "\n",
    "lin_corr_list = linear_corr_train(X_first)\n",
    "\n",
    "scales = [standard_scale]\n",
    "#scales = [quantil,power,robust,standard_scale,normal,nothing]\n",
    "\n",
    "vys = []\n",
    "\n",
    "for cur_scale in scales:\n",
    "    data = pd.DataFrame(cur_scale(X_first.drop(columns = ['shares'])),columns = X_first.drop(columns = ['shares']).columns)\n",
    "    data = pd.concat([data, X_first['shares']], axis=1)\n",
    "    for cur_change in data_changes:\n",
    "        data1 = cur_change(data,lin_corr_list)\n",
    "        X,X_val,Y,Y_val = split_data(data1)\n",
    "        tup = hreben(X,Y,X_val,Y_val)                          \n",
    "        vys.append((tup[0],tup[1],cur_scale,cur_change))\n",
    "        tup = linear(X,Y,X_val,Y_val)                          \n",
    "        vys.append((tup[0],tup[1],cur_scale,cur_change))\n",
    "        #tup = randomForest(X,Y,X_val,Y_val)                     \n",
    "        #vys.append((tup[0],tup[1],cur_scale,cur_change))\n",
    "        #tup = AdaBoost(X,Y,X_val,Y_val)                        \n",
    "        #vys.append((tup[0],tup[1],cur_scale,cur_change))\n",
    "        #tup = neural(X,Y,X_val,Y_val)                            \n",
    "        #vys.append((tup[0],tup[1],cur_scale,cur_change))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Konecna chyba je  1590.9466082487897 \n",
      "s modelem  Ridge(alpha=5.5, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001) ,\n",
      " pouzite funkce na skalovani dat :  <function standard_scale at 0x7f47881dcb70> \n",
      "a funkce na zmenu priznaku:  <function data_change_2_do at 0x7f478bed6d90>\n"
     ]
    }
   ],
   "source": [
    "# vypis nejlepsi moznosti s chybou 'median_absolute_error' s testovacimi daty \n",
    "# (pouze linearni a hrebenova regrese)\n",
    "\n",
    "limit = vys[0][0]\n",
    "final = vys[0]\n",
    "for i in vys:\n",
    "    if (i[0] < limit):\n",
    "        final = i\n",
    "        limit = i[0]\n",
    "final_error = predict(final[1],final[2](final[3](X_final_test,lin_corr_list)),Y_final_test)\n",
    "print('Konecna chyba je ',final_error,'\\ns modelem ',final[1],',\\n pouzite funkce na skalovani dat : ',final[2],'\\na funkce na zmenu priznaku: ',final[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vypocet vsech modelu s upravou dat, u kterych davaji nejlepsi vysledek\n",
    "\n",
    "lin_corr_list = linear_corr_train(X_first)\n",
    "vys1 = []\n",
    "\n",
    "data = pd.DataFrame(standard_scale(X_first.drop(columns = ['shares'])),columns = X_first.drop(columns = ['shares']).columns)\n",
    "data = pd.concat([data, X_first['shares']], axis=1)\n",
    "data1 = data_change_2_do(data,lin_corr_list)\n",
    "X,X_val,Y,Y_val = split_data(data1)\n",
    "tup = hreben(X,Y,X_val,Y_val)                       \n",
    "vys1.append((tup[0],tup[1],standard_scale,data_change_2_do))\n",
    "\n",
    "\n",
    "data = pd.DataFrame(standard_scale(X_first.drop(columns = ['shares'])),columns = X_first.drop(columns = ['shares']).columns)\n",
    "data = pd.concat([data, X_first['shares']], axis=1)\n",
    "data1 = data_change_2_do(data,lin_corr_list)\n",
    "X,X_val,Y,Y_val = split_data(data1)\n",
    "tup = linear(X,Y,X_val,Y_val)                           \n",
    "vys1.append((tup[0],tup[1],standard_scale,data_change_2_do))\n",
    "\n",
    "\n",
    "data = pd.DataFrame(nothing(X_first.drop(columns = ['shares'])),columns = X_first.drop(columns = ['shares']).columns)\n",
    "data = pd.concat([data, X_first['shares']], axis=1)\n",
    "data1 = data_change_3_do(data,lin_corr_list)\n",
    "X,X_val,Y,Y_val = split_data(data1)\n",
    "tup = randomForest(X,Y,X_val,Y_val)                     \n",
    "vys1.append((tup[0],tup[1],nothing,data_change_3_do))\n",
    "\n",
    "\n",
    "data = pd.DataFrame(power(X_first.drop(columns = ['shares'])),columns = X_first.drop(columns = ['shares']).columns)\n",
    "data = pd.concat([data, X_first['shares']], axis=1)\n",
    "data1 = data_change_3_do(data,lin_corr_list)\n",
    "X,X_val,Y,Y_val = split_data(data1)\n",
    "tup = AdaBoost(X,Y,X_val,Y_val)                         \n",
    "vys1.append((tup[0],tup[1],power,data_change_3_do))\n",
    "\n",
    "\n",
    "data = pd.DataFrame(robust(X_first.drop(columns = ['shares'])),columns = X_first.drop(columns = ['shares']).columns)\n",
    "data = pd.concat([data, X_first['shares']], axis=1)\n",
    "data1 = data_change_2_do(data,lin_corr_list)\n",
    "X,X_val,Y,Y_val = split_data(data1)\n",
    "tup = neural(X,Y,X_val,Y_val)                            \n",
    "vys1.append((tup[0],tup[1],standard_scale,data_change_2_do))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Konecna chyba je  1289.9248542037958 \n",
      "s modelem  MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(50,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=3, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False) ,\n",
      " pouzite funkce na skalovani dat :  <function standard_scale at 0x7f47881dcb70> \n",
      "a funkce na zmenu priznaku:  <function data_change_2_do at 0x7f478bed6d90>\n"
     ]
    }
   ],
   "source": [
    "# nejlepsi moznost ze vsech modelu\n",
    "# vypis chyby nad testovacimi daty\n",
    "\n",
    "limit = vys1[0][0]\n",
    "final = vys1[0]\n",
    "for i in vys1:\n",
    "    if (i[0] < limit):\n",
    "        final = i\n",
    "        limit = i[0]\n",
    "final_error1 = predict(final[1],final[2](final[3](X_final_test,lin_corr_list)),Y_final_test)\n",
    "print('Konecna chyba je ',final_error1,'\\ns modelem ',final[1],',\\n pouzite funkce na skalovani dat : ',final[2],'\\na funkce na zmenu priznaku: ',final[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
