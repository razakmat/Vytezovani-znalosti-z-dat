{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Úkol č. 2 - předzpracování dat a binární klasifikace (do 7. prosince)\n",
    "\n",
    "  * V rámci tohoto úkolu se musíte vypořádat s příznaky, které jsou různých typů.\n",
    "  * Před tím, než na nich postavíte predikční model, je třeba je nějakým způsobem převést do číselné reprezentace.\n",
    "    \n",
    "> **Úkoly jsou zadány tak, aby Vám daly prostor pro invenci. Vymyslet _jak přesně_ budete úkol řešit, je důležitou součástí zadání a originalita či nápaditost bude také hodnocena!**\n",
    "\n",
    "## Zdroj dat\n",
    "\n",
    "Budeme se zabývat predikcí přežití pasažérů Titaniku.\n",
    "K dispozici máte trénovací data v souboru **data.csv** a data na vyhodnocení v souboru **evaluation.csv**.\n",
    "\n",
    "#### Seznam příznaků:\n",
    "* survived - zda přežil, 0 = Ne, 1 = Ano, **vysvětlovaná proměnná**, kterou chcete predikovat\n",
    "* pclass - Třída lodního lístku, 1 = první, 2 = druhá, 3 = třetí\n",
    "* name - jméno\n",
    "* sex - pohlaví\n",
    "* age - věk v letech\n",
    "* sibsp\t- počet sourozenců / manželů, manželek na palubě\n",
    "* parch - počet rodičů / dětí na palubě\n",
    "* ticket - číslo lodního lístku\n",
    "* fare - cena lodního lístku\n",
    "* cabin\t- číslo kajuty\n",
    "* embarked\t- místo nalodění, C = Cherbourg, Q = Queenstown, S = Southampton\n",
    "* home.dest - Bydliště/Cíl\n",
    "\n",
    "## Pokyny k vypracování\n",
    "\n",
    "**Základní body zadání**, za jejichž (poctivé) vypracování získáte **8 bodů**:\n",
    "  * V Jupyter notebooku načtěte data ze souboru **data.csv**. Vhodným způsobem si je rozdělte na trénovací, testovací a případně i validační množinu.\n",
    "  * Projděte si jednotlivé příznaky a transformujte je do vhodné podoby pro použití ve vybraném klasifikačním modelu.\n",
    "  * Podle potřeby si můžete vytvářet nové příznaky (na základě existujících), například tedy můžete vytvořit příznak měřící délku jména. Některé příznaky můžete také úplně zahodit.\n",
    "  * Nějakým způsobem se vypořádejte s chybějícími hodnotami.\n",
    "  * Následně si vyberte vhodný klasifikační model z přednášek. Najděte vhodné hyperparametry a určete jeho přesnost (accuracy) na trénovací množině. Také určete jeho přesnost na testovací množině.\n",
    "  * Načtěte vyhodnocovací data ze souboru **evaluation.csv**. Napočítejte predikce pro tyto data (vysvětlovaná proměnná v nich již není). Vytvořte **results.csv** soubor, ve kterém tyto predikce uložíte do dvou sloupců: ID, predikce přežití. Tento soubor nahrajte do repozitáře.\n",
    "\n",
    "**Další body zadání** za případné další body  (můžete si vybrat, maximum bodů za úkol je každopádně 12 bodů):\n",
    "  * (až +4 body) Aplikujte všechny klasifikační modely z přednášek a určete (na základě přesnosti na validační množině), který je nejlepší. Přesnost tohoto nejlepšího modelu odhadněte pomocí testovací množiny. K predikcím na vyhodnocovacích datech využijte tento model.\n",
    "  * (až +4 body) Zkuste použít nějaké (alespoň dvě) netriviální metody doplňování chybějících hodnot u věku. Zaměřte na vliv těchto metod na přesnost predikce výsledného modelu. K predikcím na vyhodnocovacích datech využijte ten přístup, který Vám vyjde jako nejlepší.\n",
    "\n",
    "## Poznámky k odevzdání\n",
    "\n",
    "  * Řiďte se pokyny ze stránky https://courses.fit.cvut.cz/BI-VZD/homeworks/index.html.\n",
    "  * Odevzdejte nejen Jupyter Notebook, ale i _csv_ soubor(y) s predikcemi pro vyhodnocovací data.\n",
    "  * Opravující Vám může umožnit úkol dodělat či opravit a získat tak další body. První verze je ale důležitá a bude-li odbytá, budete za to penalizováni**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.misc import logsumexp\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_rows', 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upravaDat(data):\n",
    "    display(data[data.drop(['cabin','age','home.dest'],axis=1).isnull().any(axis=1)])\n",
    "    data = fare(data)\n",
    "    data = embarked(data)    \n",
    "    data = pclass(data)\n",
    "    data = name(data)\n",
    "    data = sex(data)    \n",
    "    data = sibsp(data)\n",
    "    data = parch(data)\n",
    "    data = ticket(data)\n",
    "    data = cabin(data)\n",
    "    data = age(data)\n",
    "    data = home_dest(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pclass(data):\n",
    "    print('\\n-----------pclass-------\\n')\n",
    "    display(data['pclass'].value_counts())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name(data):\n",
    "    data.insert(3,'titul',data.iloc[:,3].str.split(' ').str[1])\n",
    "    for i in data.index:\n",
    "        if data.loc[i,'titul'] != 'Mr.' and data.loc[i,'titul'] != 'Miss.' and data.loc[i,'titul'] != 'Mrs.' and data.loc[i,'titul'] != 'Master.':\n",
    "            data.loc[i,'titul'] = 'Other'\n",
    "    data = data.drop(['name'],axis=1)\n",
    "    data['titul'] = data['titul'].map({'Mr.' : 0 , 'Miss.' : 1 , 'Mrs.' : 2 , 'Master.' : 3 , 'Other' : 4 })\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sex(data):\n",
    "    data['sex'] = data['sex'].map({'female' : 0 , 'male' : 1 })\n",
    "    data['sex'] = data['sex'].astype('int64')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age(data):\n",
    "    print('\\n-----------age-------\\n')\n",
    "    display(data.corr().age)\n",
    "    \n",
    "    for i in np.arange(1, 4, 1):\n",
    "        for j in np.arange(0, 7, 1):\n",
    "            data.loc[(data['age'].isnull()) & (data['pclass'] == i) & (data['sibsp'] == j), 'age'] = data[ (data['pclass']== i) & (data['sibsp'] == j) ]['age'].mean()\n",
    "    \n",
    "    data['age'] = pd.cut(data['age'].astype('int64'),bins=[0,10,18,25,30,45,55,1000],labels=[0,1,2,3,4,5,6],include_lowest=True)\n",
    "    data['age'] = data['age'].astype('int64')\n",
    "    display(data['age'].value_counts())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sibsp(data):\n",
    "\n",
    "    data.loc[data['sibsp'] > 4, 'sibsp'] = 5\n",
    "\n",
    "    print('\\n-----------sibsp-------\\n')\n",
    "    display(data['sibsp'].value_counts())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parch(data):\n",
    "\n",
    "    data.loc[data['parch'] > 4, 'parch'] = 5\n",
    "    print('\\n-----------parch-------\\n')\n",
    "    display(data['parch'].value_counts())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ticket(data):\n",
    "    data = data.drop(['ticket'],axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fare(data):\n",
    "    data['fare'] = data['fare'].fillna(data[data['pclass']==3]['fare'].value_counts().keys()[0])\n",
    "    data['fare'] = pd.cut(data['fare'].astype('int64'),bins=[0,10,30,70,100,1000],labels=[0,1,2,3,4],include_lowest=True)\n",
    "    data['fare'] = data['fare'].astype('int64')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cabin(data):\n",
    "    print('\\n-----------cabin-------\\n')\n",
    "    data.insert(11,'paluba',data.loc[:,'cabin'].str[0])\n",
    "    data.insert(11,'pozice',data.loc[:,'cabin'].str[1:].str.split(' ').str[0])\n",
    "    data = data.drop(['cabin'],axis=1)\n",
    "    for i in data.index:\n",
    "        if data.loc[i,'pozice'] == '':\n",
    "            data.loc[i,'pozice'] = np.nan\n",
    "    data['pozice'] = data['pozice'].fillna(int(data[data.notnull().pozice]['pozice'].astype('int64').mean()))\n",
    "    data['paluba'] = data['paluba'].fillna('C')    \n",
    "    data.loc[data['paluba'] > 'F', 'paluba'] = 'G'\n",
    "    display(data['paluba'].value_counts())\n",
    "    data['paluba'] = data['paluba'].map({'A' : 0 , 'B' : 1 , 'C' : 2 , 'D' : 3 , 'E' : 4 , 'F' : 5 , 'G' : 6})\n",
    "    \n",
    "    data['pozice'] = pd.cut(data['pozice'].astype('int64'),bins=[0,20,45,50,100,1000],labels=[0,1,2,3,4],include_lowest=True)\n",
    "    data['pozice'] = data['pozice'].astype('int64')\n",
    "    \n",
    "    display(data['pozice'].value_counts())\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embarked(data):\n",
    "    data['embarked'] = data['embarked'].fillna(data['embarked'].value_counts().keys()[0])\n",
    "    print('\\n-----------embarked-------\\n')\n",
    "    display(data['embarked'].value_counts())\n",
    "    data['embarked'] = data['embarked'].map({'S' : 1 , 'C' : 0 , 'Q' : 2})\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def home_dest(data):\n",
    "    data = data.drop(['home.dest'],axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forest(data):\n",
    "    X, X_test, Y, Y_test = train_test_split(data.drop(columns = ['ID', 'survived']), data['survived'], test_size=0.25, random_state=42)\n",
    "    Xtrain, Xval, Ytrain, Yval = train_test_split(X, Y, test_size=0.25, random_state=235)\n",
    "    param_grid = {\n",
    "        'n_estimators': range(1,100,5),\n",
    "        'max_depth': range(1,6)\n",
    "    }\n",
    "    param_comb = ParameterGrid(param_grid)\n",
    "    val_acc = []\n",
    "    for param in param_comb:\n",
    "        ret = RandomForestClassifier(**param)\n",
    "        ret.fit(Xtrain, Ytrain)\n",
    "        val_acc.append(math.sqrt(metrics.mean_squared_error(Yval, ret.predict(Xval))))\n",
    "    best_param = param_comb[np.argmin(val_acc)]\n",
    "    ret = RandomForestClassifier(**best_param)\n",
    "    ret.fit(Xtrain, Ytrain)\n",
    "    print('accuracy score (train): {0:.2f}'.format(metrics.accuracy_score(Y, ret.predict(X))*100),'%')\n",
    "    print('accuracy score (test): {0:.2f}'.format(metrics.accuracy_score(Y_test, ret.predict(X_test))*100),'%')\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "data.info()\n",
    "data = upravaDat(data)\n",
    "data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate = pd.read_csv('evaluation.csv')\n",
    "evaluate.info()\n",
    "evaluate = upravaDat(evaluate)\n",
    "evaluate.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = forest(data)\n",
    "result = pd.DataFrame(\n",
    "    {'ID': evaluate['ID'],\n",
    "     'predikce_preziti': ret.predict(evaluate.drop(columns = ['ID']))\n",
    "    })\n",
    "result.to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
